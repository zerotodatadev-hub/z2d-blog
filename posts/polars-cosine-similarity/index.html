<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Calculating cosine similarity between consecutive row embeddings in Polars — starting naïve, then making it pretty and fast with vectorized arrays.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Cosine Similarity in Polars: From Naive to Vectorized | ZERO TO DATA</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#2563EB">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://z2d.io/posts/polars-cosine-similarity/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><link rel="stylesheet" type="text/css" href="assets/css/code.css" id="code-theme">
<script src="assets/js/code-toggle.js"></script><meta name="author" content="Max @ Z2D">
<link rel="prev" href="../another-post/" title="another post" type="text/html">
<meta property="og:site_name" content="ZERO TO DATA">
<meta property="og:title" content="Cosine Similarity in Polars: From Naive to Vectorized">
<meta property="og:url" content="https://z2d.io/posts/polars-cosine-similarity/">
<meta property="og:description" content="Calculating cosine similarity between consecutive row embeddings in Polars — starting naïve, then making it pretty and fast with vectorized arrays.">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-09-11T10:00:00Z">
<meta property="article:tag" content="data-engineering">
<meta property="article:tag" content="embeddings">
<meta property="article:tag" content="performance">
<meta property="article:tag" content="polars">
<meta property="article:tag" content="python">
<meta property="article:tag" content="vectorization">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">ZERO TO DATA</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.md" id="sourcelink" class="nav-link">Source</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Cosine Similarity in Polars: From Naive to Vectorized</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Max @ Z2D
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2025-09-11T10:00:00Z" itemprop="datePublished" title="2025-09-11 10:00">2025-09-11 10:00</time></a>
            </p>
            
        <p class="sourceline"><a href="index.md" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <h3>Why I Wrote This</h3>
<p>I needed to compute cosine similarity between word embeddings of consecutive rows in a large dataset. The goal was simple: detect how much the embedding at row i resembles the embedding at row i+1. I started with a quick, naïve version to validate correctness and then refactored to a vectorized, production‑ready approach in Polars.</p>
<p>Mindset I follow: make it work → make it pretty → make it fast. Don’t pre-optimize; ship something correct first, then iterate.</p>
<h3>The Setup</h3>
<ul>
<li>The input is a Polars <code>DataFrame</code> with an <code>embedding</code> column.</li>
<li>Each <code>embedding</code> is a fixed‑length list of floats (e.g., 384‑d or 768‑d).</li>
<li>We want a new column <code>cosine_similarity</code> comparing each row’s embedding with the next row’s embedding.</li>
</ul>
<p>For clarity, I show two implementations:</p>
<p>1) a naïve, <code>map_elements</code>/Python approach for a proof of concept
2) a vectorized, array‑based approach that is much faster on large data</p>
<h3>Naïve First: Make It Work</h3>
<p>This version uses <code>pl.struct</code> to package multiple columns per row and <code>map_elements</code> to call a small Python function. It’s straightforward and great for getting the logic right.</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compute_cosine</span><span class="p">(</span><span class="n">vec_1</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">vec_2</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="c1"># handle cases where a vector is missing (eg. last entry because of shift)</span>
    <span class="k">if</span> <span class="n">vec_1</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">vec_2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># cosine similarity calculation with numpy</span>
    <span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vec_1</span><span class="p">)</span>
    <span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vec_2</span><span class="p">)</span>
    <span class="n">cosine</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v2</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">cosine</span>


<span class="k">def</span><span class="w"> </span><span class="nf">calculate_cosine_similarity_naive</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="c1"># shift the embedding before calculation of the vector similarity</span>
    <span class="c1"># with the next row element</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">([</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"embedding"</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"next_embedding"</span><span class="p">)])</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="c1"># select required columns as struct. Allows dict-like usage in lambda</span>
            <span class="n">pl</span><span class="o">.</span><span class="n">struct</span><span class="p">((</span><span class="s2">"embedding"</span><span class="p">,</span> <span class="s2">"next_embedding"</span><span class="p">))</span>
            <span class="o">.</span><span class="n">map_elements</span><span class="p">(</span>  <span class="c1"># iteration over entries (comparable to pandas .apply() )</span>
                <span class="c1"># parametrize the function for calculation of the cosine similarity</span>
                <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">_compute_cosine</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s2">"embedding"</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="s2">"next_embedding"</span><span class="p">]),</span>
                <span class="n">return_dtype</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">Float32</span><span class="p">,</span>  <span class="c1"># specify the return</span>
                <span class="n">returns_scalar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"cosine_similarity"</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>

<p>Why this first?</p>
<ul>
<li>It’s easy to read and verify.</li>
<li>
<code>pl.struct</code> cleanly passes multiple row fields into a single function.</li>
<li>Perfect for a small sample to check the math and edge cases (e.g., last row → <code>None</code>).</li>
</ul>
<p>Trade-offs:</p>
<ul>
<li>It iterates in Python space, so it’s slower on large datasets.</li>
<li>It won’t fully leverage Polars’ vectorized execution engine.</li>
</ul>
<h3>Make It Pretty and Fast: Vectorized Arrays</h3>
<p>Once the logic looked good, I refactored to a vectorized implementation. The key is to convert list embeddings into fixed-size array dtype and then use elementwise arithmetic plus <code>arr.sum()</code> to compute dot products and norms efficiently.</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="k">def</span><span class="w"> </span><span class="nf">calculate_cosine_similarity_optimized</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="c1"># Determine the embedding length from the first row</span>
    <span class="n">embedding_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"embedding"</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="n">similarity</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
            <span class="c1"># shift the embedding before calculation of the vector similarity</span>
            <span class="c1"># with the next row element</span>
            <span class="p">[</span>
                <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"embedding"</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"current_embedding"</span><span class="p">),</span>
                <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"embedding"</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"next_embedding"</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="c1"># convert both embedding columns to fixed-size arrays for vectorized ops</span>
                <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"current_embedding"</span><span class="p">)</span>
                <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="n">embedding_length</span><span class="p">)</span>
                <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"current_array"</span><span class="p">),</span>
                <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"next_embedding"</span><span class="p">)</span>
                <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="n">embedding_length</span><span class="p">)</span>
                <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"next_array"</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="c1"># dot product via elementwise multiply + sum across the array</span>
                <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"current_array"</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"next_array"</span><span class="p">))</span>
                <span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"dot_product"</span><span class="p">),</span>

                <span class="c1"># current norm: sqrt(sum(current_array * current_array))</span>
                <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"current_array"</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"current_array"</span><span class="p">))</span>
                <span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
                <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"current_norm"</span><span class="p">),</span>

                <span class="c1"># next norm: sqrt(sum(next_array * next_array))</span>
                <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"next_array"</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"next_array"</span><span class="p">))</span>
                <span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
                <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"next_norm"</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="c1"># cosine similarity = dot / (||a|| * ||b||)</span>
                <span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"dot_product"</span><span class="p">)</span>
                    <span class="o">/</span> <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"current_norm"</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">"next_norm"</span><span class="p">))</span>
                <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">"cosine_similarity"</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">similarity</span>
</pre></div>

<p>Why this is faster:</p>
<ul>
<li>Breaking the computation into simple vector expressions lets Polars optimize execution.</li>
<li>Converting lists to <code>array</code> dtype enables true elementwise arithmetic and <code>arr.sum()</code> reductions.</li>
<li>Everything runs inside Polars’ engine, minimizing Python overhead.</li>
</ul>
<h3>Small Example</h3>
<p>Here’s a minimal example you can run to see both versions side-by-side:</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">"id"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s2">"embedding"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">naive</span> <span class="o">=</span> <span class="n">calculate_cosine_similarity_naive</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">optimized</span> <span class="o">=</span> <span class="n">calculate_cosine_similarity_optimized</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">naive</span><span class="o">.</span><span class="n">select</span><span class="p">([</span><span class="s2">"id"</span><span class="p">,</span> <span class="s2">"cosine_similarity"</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimized</span><span class="o">.</span><span class="n">select</span><span class="p">([</span><span class="s2">"id"</span><span class="p">,</span> <span class="s2">"cosine_similarity"</span><span class="p">]))</span>
</pre></div>

<p>Both versions produce a <code>cosine_similarity</code> column. The last row will typically be <code>null</code> because there is no “next” row after the final one.</p>
<h3>Key Ideas to Reuse</h3>
<ul>
<li>Breaking steps down: dot product and norms are separate, simple expressions. This makes the intent clear and enables Polars to optimize effectively.</li>
<li>
<code>pl.array</code> via <code>list.to_array(n)</code>: converting lists to fixed-size arrays unlocks elementwise ops and fast reductions like <code>.arr.sum()</code>.</li>
<li>
<code>pl.struct(...)</code>: the easiest way to pass multiple row fields into a single <code>map_elements</code> function in the naïve version.</li>
<li>
<code>shift(-1)</code>: aligns each row with the next row for pairwise comparisons across consecutive entries.</li>
</ul>
<p>Edge cases and correctness:</p>
<ul>
<li>Ensure all embeddings have the same length before calling <code>list.to_array(n)</code>.</li>
<li>If your last row’s <code>next_embedding</code> is null, the final <code>cosine_similarity</code> should be null as well — that’s expected.</li>
<li>If you have missing embeddings earlier in the column, decide whether to fill, drop, or carry forward before computing similarity.</li>
</ul>
<h3>Lessons Learned / Takeaways</h3>
<ul>
<li>Make it work → make it pretty → make it fast. Start naïve to validate logic and edge cases, then vectorize.</li>
<li>Prefer vectorized Polars operations over row-wise Python loops for performance.</li>
<li>Convert list embeddings to fixed-size arrays to use elementwise arithmetic and <code>.arr.sum()</code>.</li>
<li>Use <code>pl.struct</code> when you need to feed multiple columns into a single row-wise function.</li>
<li>Keep computations explicit and composable; it’s easier to reason about, debug, and optimize.</li>
</ul>
</div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/data-engineering/" rel="tag">data-engineering</a></li>
            <li><a class="tag p-category" href="../../categories/embeddings/" rel="tag">embeddings</a></li>
            <li><a class="tag p-category" href="../../categories/performance/" rel="tag">performance</a></li>
            <li><a class="tag p-category" href="../../categories/polars/" rel="tag">polars</a></li>
            <li><a class="tag p-category" href="../../categories/python/" rel="tag">python</a></li>
            <li><a class="tag p-category" href="../../categories/vectorization/" rel="tag">vectorization</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../another-post/" rel="prev" title="another post">Previous post</a>
            </li>
        </ul></nav></aside></article><!--End of body content--><footer id="footer">
            Contents © 2025         <a href="mailto:zerotodata.dev@gmail.com">Max @ Z2D</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
